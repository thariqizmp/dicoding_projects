# -*- coding: utf-8 -*-
"""Proyek Pertama _Membuat Model NLP dengan TensorFlow_Thariq Iskandar ZMP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IFnvlAFrU0IIdgULb41ayEb8Ovc6V1GR

# **Proyek Pertama : Membuat Model NLP dengan TensorFlow**
### Nama : Thariq Iskandar Zulkarnain M P
### No. Pendaftaran : 0182180151-57
### Email : thariqiskandar9@gmail.com
### No. Handphone : 6281332409623
### Tema Pelatihan : FGA Machine Learning (IBM)
"""

#membuat kelas callback
import tensorflow as tf

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.9 and logs.get('val_accuracy')>0.9):
      print("\nAkurasi training set dan validation set telah mencapai >90%!")
      self.model.stop_training = True
callbacks = myCallback()

#input data bbc text yang telah didownload dari kaggle
import pandas as pd
df = pd.read_csv('bbc-text.csv')
df

#melakukan proses one-hot encoding pada kolom category
new_category = pd.get_dummies(df.category)
new_df = pd.concat([df, new_category], axis=1)
new_df = new_df.drop(columns='category')
new_df

#mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array
text = new_df['text'].values
label = new_df[['business', 'entertainment', 'politics', 'sport', 'tech']].values

#bagi data training dan data testing dengan ratio 80:20
from sklearn.model_selection import train_test_split
text_latih, text_test, label_latih, label_test = train_test_split(text, label, test_size=0.2, random_state=42)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

#mengubah setiap kata pada dataset ke dalam bilangan numerik dengan fungsi Tokenizer
tokenizer = Tokenizer(num_words=5000, oov_token='x', filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n')
tokenizer.fit_on_texts(text_latih) 
tokenizer.fit_on_texts(text_test)

#konversi setiap sampel menjadi sequence
sekuens_latih = tokenizer.texts_to_sequences(text_latih)
sekuens_test = tokenizer.texts_to_sequences(text_test)

#menggunakan fungsi pad_sequences agar setiap sequence sama panjang
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf

#membangun arsitektur neural network
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=64),
    tf.keras.layers.LSTM(128),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(5, activation='softmax')  #dataset terdiri dari 5 kelas
])

#memanggil fungsi compile
model.compile(loss='categorical_crossentropy',  #dataset terdiri dari 5 kelas
              optimizer='adam',
              metrics=['accuracy'])

#melatih model
num_epochs = 30
history = model.fit(padded_latih, 
                    label_latih,
                    batch_size=128,
                    epochs=num_epochs, 
                    callbacks=[callbacks],
                    validation_data=(padded_test, label_test),
                    verbose=2)

import matplotlib.pyplot as plt

#plot train & validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Plot')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="upper right")
plt.show()

#plot train & validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Plot')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.show()